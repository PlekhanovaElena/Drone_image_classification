{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import tifffile as tiff # for reading tiff images\n",
    "\n",
    "from tqdm.notebook import tqdm # for the beautiful progress-bars\n",
    "from myfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ORIGINAL_IMAGES = \"../../../Nextcloud2/\" # the folder with all the images\n",
    "MSP_FOLDER = \"./data/drone_msp_numpy/\" # the folder with preprocessed MSP images\n",
    "PATH_LABELS = \"./data/labels_MSP_4classes.csv\" # the file with labelled points\n",
    "PATH_META_LANDCOVER = \"./data/msp_meta_landcover.csv\"\n",
    "PATH_RESULT_JPG = \"./data/MSP_masks_jpg/\"\n",
    "PATH_RESULT_MSP = './data/MSP_masks_tiff/'\n",
    "\n",
    "# Creating the ou tput directories if they do not exist\n",
    "if not os.path.exists(PATH_RESULT_MSP):  \n",
    "    os.mkdir(PATH_RESULT_MSP)\n",
    "if not os.path.exists(PATH_RESULT_JPG):  \n",
    "    os.mkdir(PATH_RESULT_JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drfiles = []\n",
    "for path, subdirs, files in os.walk(PATH_ORIGINAL_IMAGES):\n",
    "    for name in files:\n",
    "        drfiles = drfiles + [os.path.join(path, name)]\n",
    "grefiles = [drfiles[i] for i in range(len(drfiles)) if any(x in drfiles[i] for x in [\"_nir\"])]\n",
    "grefiles = np.array(grefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the metadata about whether soil, water or snow are present on the picture \n",
    "df = pd.read_csv(PATH_META_LANDCOVER, index_col=0)\n",
    "dark_imgs = df.name[df.dark_image == 1] # Listing dark images\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading out the labelled points (training data)\n",
    "labdat = pd.read_csv(PATH_LABELS, header = None)\n",
    "labdat = labdat[[3,0,2,1]]\n",
    "labdat.columns = [\"imname\", \"label\", \"x\", \"y\"]\n",
    "labdat[\"imname\"] = [x.split(\"_false\")[0] for x in labdat.imname.values]\n",
    "labdat[\"region\"] = [x.split(\"_\")[1] for x in labdat.imname.values]\n",
    "# Putting dark images in separate regions\n",
    "labdat.loc[np.isin(labdat.imname,dark_imgs), \"region\"] = labdat.region[np.isin(labdat.imname,dark_imgs)] + \"_dark\"\n",
    "labdat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imnames = np.unique(labdat[\"imname\"])\n",
    "# Normalizing each image to its 99th percentile\n",
    "for name_im in tqdm(train_imnames):\n",
    "    msp_names = names_in_folder(name_im, MSP_FOLDER)\n",
    "    msp = np.load(MSP_FOLDER + msp_names[0])\n",
    "    inds_im = labdat.imname == name_im\n",
    "    labdat.loc[inds_im, [\"r\",\"g\", \"reg\", \"nir\"]] = msp[labdat[inds_im].x, labdat[inds_im].y, :]/np.quantile(msp, 0.99)\n",
    "    \n",
    "# Calculating the indexes\n",
    "labdat[\"ndvi\"] = (labdat[\"nir\"] - labdat[\"r\"])/(labdat[\"nir\"] + labdat[\"r\"])\n",
    "labdat[\"nir_r\"] = labdat[\"nir\"] - labdat[\"r\"]\n",
    "labdat[\"sumb\"] = labdat[\"nir\"] + labdat[\"r\"] + labdat[\"r\"]\n",
    "labdat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfunctions import *\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif_imname_region(name_im, labdat, grefiles, \\\n",
    "                          featurenames = [\"ndvi\", \"nir_r\", \"sumb\",\"r\",\"nir\",\"g\", \"reg\"], excl_low_imp = True):\n",
    "    \n",
    "    ## Getting information abot the image\n",
    "    regim = name_im.split(\"_\")[1] # determining the region of the image\n",
    "    nam = name_im.split(\"_msp\")[0]\n",
    "    metadat = df[df.name == nam]\n",
    "    if metadat.dark_image.item() == 1:\n",
    "        regim = regim + \"_dark\"\n",
    "        \n",
    "    ## Reading out an image\n",
    "    msp_names = names_in_folder(name_im, MSP_FOLDER)\n",
    "    msp = np.load(MSP_FOLDER + msp_names[0]) # reading out preprocessed image\n",
    "    msp3 = image_minmax(msp[:,:,[3,0,1]]) # creating falsecolor image (NIR, red, green)\n",
    "    \n",
    "    \n",
    "    ## Fitting Random Forest classifier and predicting the labels\n",
    "    dct = fitting_rf_for_region(labdat, regim, featurenames, excl_low_imp) # fitting RF on training data\n",
    "    clf = dct[\"clf\"]\n",
    "    featurenames = dct[\"featurenames\"]\n",
    "    \n",
    "    dim = calculating_features(msp, featurenames) #calculating the indexes\n",
    "    prlab = clf.predict(dim) # predicting labels for the image\n",
    "    prlab = prlab.reshape((msp.shape[0],msp.shape[1])) # reshaping prediction back to the image shape\n",
    "    \n",
    "\n",
    "    # threshold for taking the superpixel, 0 if there is no water\n",
    "    const_water = metadat.const_water.item() \n",
    "    # threshold for taking the superpixel, 0 if we don't want to add superpixels\n",
    "    const_soil = metadat.const_soil.item()  \n",
    "    \n",
    "    if (const_water > 0) | (const_soil > 0): # if we use the superpixel postrocessing\n",
    "        img, segm, centers_norm = slic_segm(msp3, n_segments=50000, compactness = 8) # Segmenting the image\n",
    "        clust_segm1 = spat_segm(msp, img, segm, centers_norm, n_clust1=1000) # Clustering the superpixels\n",
    "\n",
    "        if const_water > 0: # if tehre is water\n",
    "            # we replace water by superpixels, containing (fraction of water) > const_water\n",
    "            prlab = create_mask(prlab, clust_segm1, const_water, \"water\", replace = True) \n",
    "            \n",
    "        if const_soil > 0: # if tehre is soil and we want to add superpixels\n",
    "            # we add to soil the superpixels, containing (fraction of soil) > const_soil\n",
    "            prlab = create_mask(prlab, clust_segm1, const_soil, \"soil\")\n",
    "    \n",
    "    ## Saving the masks\n",
    "    for maskname in [\"water\", \"soil\", \"snow\"]:\n",
    "        if metadat[maskname].item() == 1: # if this landcover is present, save the mask\n",
    "            save_mask(prlab, maskname, nam, grefiles, PATH_RESULT_MSP)\n",
    "        else: # else - replace it with vegetation\n",
    "            prlab[prlab == maskname] = \"vegetation\"\n",
    "        \n",
    "    save_mask(prlab, \"vegetation\", nam, grefiles, PATH_RESULT_MSP)\n",
    "    \n",
    "    plot_clfres(prlab, msp3, name_im, path_result = PATH_RESULT_JPG) # plotting the result and saving image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, name_im in tqdm(enumerate(os.listdir(MSP_FOLDER))):\n",
    "    print(i, name_im)\n",
    "    %time classif_imname_region(name_im, labdat, grefiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
