{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import tifffile as tiff # for reading tiff images\n",
    "\n",
    "from tqdm.notebook import tqdm # for the beautiful progress-bars\n",
    "from myfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ORIGINAL_IMAGES = \"../../../Nextcloud2/\" # the folder with all the images\n",
    "RGB_FOLDER = \"./data/drone_rgb/\" # the folder with preprocessed RGB images\n",
    "PATH_LABELS = \"./data/labels_RGB_4classes.csv\" # the file with labelled points\n",
    "PATH_META_LANDCOVER = \"./data/meta_rgb_landcover.csv\"\n",
    "PATH_RESULT_JPG = \"./data/RGB_masks_jpg/\"\n",
    "PATH_RESULT_RGB = './data/RGB_masks_tiff/'\n",
    "\n",
    "# Creating the ou tput directories if they do not exist\n",
    "if not os.path.exists(PATH_RESULT_RGB):  \n",
    "    os.mkdir(PATH_RESULT_RGB)\n",
    "if not os.path.exists(PATH_RESULT_JPG):  \n",
    "    os.mkdir(PATH_RESULT_JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drfiles = []\n",
    "for path, subdirs, files in os.walk(RGB_FOLDER):\n",
    "    for name in files:\n",
    "        drfiles = drfiles + [os.path.join(path, name)]\n",
    "grefiles = [drfiles[i] for i in range(len(drfiles)) if any(x in drfiles[i] for x in [\"_rgb\"])]\n",
    "grefiles = np.array(grefiles)\n",
    "len(grefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the metadata about whether soil, water or snow are present on the picture \n",
    "df = pd.read_csv(PATH_META_LANDCOVER, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading out the labelled points (training data)\n",
    "labdat = pd.read_csv(PATH_LABELS, header = None)\n",
    "labdat = labdat[[3,0,2,1]]\n",
    "labdat.columns = [\"imname\", \"label\", \"x\", \"y\"]\n",
    "labdat[\"imname\"] = [x.split(\"_rgb\")[0] for x in labdat.imname.values]\n",
    "labdat[\"region\"] = [x.split(\"_\")[1] for x in labdat.imname.values]\n",
    "labdat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imnames = np.unique(labdat[\"imname\"])\n",
    "# Normalizing each image to its 99th percentile\n",
    "for name_im in tqdm(train_imnames):\n",
    "    rgb_names = names_in_folder(name_im, RGB_FOLDER)[0]\n",
    "    im = tiff.imread(RGB_FOLDER + rgb_names)/255\n",
    "    inds_im = labdat.imname == name_im\n",
    "    labdat.loc[inds_im, [\"r\",\"g\", \"b\"]] = im[labdat[inds_im].x, labdat[inds_im].y, :]/np.quantile(im, 0.99)\n",
    "    \n",
    "# Calculating the indexes\n",
    "labdat[\"rg\"] = (labdat[\"r\"])/(labdat[\"g\"])\n",
    "labdat[\"br\"] = (labdat[\"b\"])/(labdat[\"r\"] + labdat[\"g\"] + labdat[\"b\"])\n",
    "labdat[\"sumb\"] = labdat[\"r\"] + labdat[\"g\"] + labdat[\"b\"]\n",
    "labdat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif_imname_region(name_im, labdat, grefiles, \\\n",
    "                          featurenames = [\"rg\", \"br\", \"sumb\",\"r\",\"g\", \"b\"], excl_low_imp = True):\n",
    "    \n",
    "    ## Getting information abot the image\n",
    "    regim = name_im.split(\"_\")[1] # determining the region of the image\n",
    "    nam = name_im.split(\"_rgb\")[0]\n",
    "    metadat = df[df.name == name_im]\n",
    "        \n",
    "    ## Reading out an image\n",
    "    rgb_names = names_in_folder(name_im, RGB_FOLDER)[0]\n",
    "    im = tiff.imread(RGB_FOLDER + rgb_names)/255 # reading out preprocessed image\n",
    "    \n",
    "    \n",
    "    ## Fitting Random Forest classifier and predicting the labels\n",
    "    dct = fitting_rf_for_region(labdat, regim, featurenames, excl_low_imp) # fitting RF on training data\n",
    "    clf = dct[\"clf\"]\n",
    "    featurenames = dct[\"featurenames\"]\n",
    "    \n",
    "    dim = calculating_features_rgb(im, featurenames) # calculating the indexes\n",
    "    prlab = clf.predict(dim) # predicting labels for the image\n",
    "    prlab = prlab.reshape((im.shape[0],im.shape[1])) # reshaping prediction back to the image shape\n",
    "    \n",
    "\n",
    "    # threshold for taking the superpixel, 0 if there is no water\n",
    "    const_water = metadat.const_water.item() \n",
    "    # threshold for taking the superpixel, 0 if we don't want to add superpixels\n",
    "    const_soil = metadat.const_soil.item()  \n",
    "    \n",
    "    if (const_water > 0) | (const_soil > 0): # if we use the superpixel postrocessing\n",
    "        img, segm, centers_norm = slic_segm(im, n_segments=50000, compactness = 8) # Segmenting the image\n",
    "        clust_segm1 = spat_segm(im, img, segm, centers_norm, n_clust1=1000) # Clustering the superpixels\n",
    "\n",
    "        if const_water > 0: # if tehre is water\n",
    "            # we replace water by superpixels, containing (fraction of water) > const_water\n",
    "            prlab = create_mask(prlab, clust_segm1, const_water, \"water\", replace = True) \n",
    "            \n",
    "        if const_soil > 0: # if tehre is soil and we want to add superpixels\n",
    "            # we add to soil the superpixels, containing (fraction of soil) > const_soil\n",
    "            prlab = create_mask(prlab, clust_segm1, const_soil, \"soil\")\n",
    "    \n",
    "    ## Saving the masks\n",
    "    for maskname in [\"water\", \"soil\", \"snow\"]:\n",
    "        if metadat[maskname].item() == 1: # if this landcover is present, save the mask\n",
    "            save_mask(prlab, maskname, nam, grefiles, PATH_RESULT_RGB)\n",
    "        else: # else - replace it with vegetation\n",
    "            prlab[prlab == maskname] = \"vegetation\"\n",
    "        \n",
    "    save_mask(prlab, \"vegetation\", nam, grefiles, PATH_RESULT_RGB)\n",
    "    \n",
    "    plot_clfres(prlab, im*255, name_im, path_result = PATH_RESULT_JPG) # plotting the result and saving image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, name_im in tqdm(enumerate(os.listdir(RGB_FOLDER)[0:2])):\n",
    "    print(i, name_im)\n",
    "    %time classif_imname_region(name_im, labdat, grefiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
